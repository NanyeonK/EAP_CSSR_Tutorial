{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis, rankdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch2. Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important for presentation of summary statistics represents a trade-off between showing enough results to give the reader and not presenting so much that the reader is overwhelmed.\n",
    "\n",
    "In this part, show the typical summary statistis tor cross-sectional distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary statistics procedure consists of two sterps:\n",
    "  1. For each time period $t$, certain charaacteristics of cross-sectional distribution of the given variable, $X$, are calculated.   \n",
    "  2. The time series properties of the periodic cross-sectional characteristics are calculated.    \n",
    "  The most importanr time series properties are the mean.   \n",
    "  The mean means the average value of the cross-sectional characteristic over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Periodic Cross-Sectional Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step for cross-sectional summary statistics.   \n",
    "\n",
    "Calculate in one period, $t-n$, $t-(n-1)$, ..., $t$.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean, standard deviation, skewness, excess kurtosis, minimum, median, maximum, and selected additional percentile of the distribution of values of $X$, where each of these statistics is calculated over all available values of $X$ in time $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we let statistics as:\n",
    "* $Mean_t$   : mean\n",
    "* $SD_t$     : standard deviation\n",
    "* $Skew_t$   : skewneww\n",
    "* $Kurt_t$   : kutosis\n",
    "* $Min_t$    : minimum value\n",
    "* $Median_t$ : median value\n",
    "* $Max_t$    : maximum value of $X$ in period $t$\n",
    "\n",
    "Percentile as:\n",
    "* $P5_t$     : 5th percentile\n",
    "* $P25_t$    : 25th percentile\n",
    "* $P75_t$    : 75th percentile\n",
    "* $P95_t$    : 95th percentile\n",
    "\n",
    "Extreme values:\n",
    "* $P1_t$     : 95th percentile\n",
    "* $P2_t$     : 2th percentile\n",
    "* $P3_t$     : 3th percentile\n",
    "* $P4_t$     : 4th percentile\n",
    "\n",
    "* $P96_t$    : 96th percentile\n",
    "* $P97_t$    : 97th percentile\n",
    "* $P98_t$    : 98th percentile\n",
    "* $P99_t$    : 99th percentile\n",
    "\n",
    "Observation\n",
    "* $n_t$      : Valid value of $X$ is available period $t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The objectives in analyzing the summary statistics are twofold. First, the summary statistics are intended to give a basic overview of the cross-sectional properties \n",
    "# of the variables that will be used in the study. This is useful for understanding the types of entities that comprise the sample. \n",
    "# Second, the summary statistics can be used to identify any potential issues that may arise when using these variables in statistical analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_cs_stats(df, time_column, value_column, additional_percentiles=False):\n",
    "    \"\"\"\n",
    "    Calculate cross-sectional statistics for each time period, handling NaN values and reporting them.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The data frame containing the data.\n",
    "        time_column (str): The name of the column representing time periods.\n",
    "        value_column (str): The name of the column representing the values of X.\n",
    "        additional_percentiles (bool or list of float): Additional percentiles to calculate (optional).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A data frame containing the calculated statistics for each time period.\n",
    "    \"\"\"\n",
    "    # Check for NaN values and report them\n",
    "    nan_report = df[df[value_column].isna()]\n",
    "    if not nan_report.empty:\n",
    "        print(\"NaN values found in the following rows:\")\n",
    "        print(nan_report)\n",
    "    \n",
    "    # Define additional percentiles if required\n",
    "    if additional_percentiles is True:\n",
    "        additional_percentiles_list = [0.01, 0.02, 0.03, 0.04, 0.96, 0.97, 0.98, 0.99]\n",
    "    elif isinstance(additional_percentiles, list):\n",
    "        additional_percentiles_list = additional_percentiles\n",
    "    else:\n",
    "        additional_percentiles_list = []\n",
    "    \n",
    "    # Function to calculate the required statistics for a given period\n",
    "    def calc_period_stats(group):\n",
    "        group_clean = group.dropna(subset=[value_column])\n",
    "        stats = {\n",
    "            'Time': group[time_column].iloc[0],  # Time column\n",
    "            'Mean': group_clean[value_column].mean(),\n",
    "            'SD': group_clean[value_column].std(),\n",
    "            'Skew': skew(group_clean[value_column], nan_policy='omit'),\n",
    "            'Kurt': kurtosis(group_clean[value_column], nan_policy='omit'),\n",
    "            'Min': group_clean[value_column].min(),\n",
    "            'Median': group_clean[value_column].median(),\n",
    "            'Max': group_clean[value_column].max(),\n",
    "            'P5': group_clean[value_column].quantile(0.05),\n",
    "            'P25': group_clean[value_column].quantile(0.25),\n",
    "            'P75': group_clean[value_column].quantile(0.75),\n",
    "            'P95': group_clean[value_column].quantile(0.95),\n",
    "            'N': group_clean[value_column].count(),\n",
    "            'NaN_count': group[value_column].isna().sum()  # Report the number of NaN values\n",
    "        }\n",
    "        \n",
    "        for percentile in additional_percentiles_list:\n",
    "            stats[f'P{int(percentile*100)}'] = group_clean[value_column].quantile(percentile)\n",
    "        \n",
    "        return pd.Series(stats)\n",
    "    \n",
    "    # Group the data by the time column and apply the function\n",
    "    stats_df = df.groupby(time_column, group_keys=False).apply(calc_period_stats).reset_index(drop=True)\n",
    "    \n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Stage\n",
    "\n",
    "caculate the time-series averages of the periodic cross-sectional values.\n",
    "    $Mean$: time-series average of the values of $Mean_t$ over all periods $t$ in the sample.\n",
    "\n",
    "Caculate the time-series means of the corss-sectional summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ts_mean(stats_df):\n",
    "    \"\"\"\n",
    "    Calculate the time-series averages of the cross-sectional statistics.\n",
    "    \n",
    "    Args:\n",
    "        stats_df (pd.DataFrame): A data frame containing cross-sectional statistics for each time period.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: A series containing the time-series averages of the cross-sectional statistics.\n",
    "    \"\"\"\n",
    "    # Exclude the time column for averaging\n",
    "    stats_to_average = stats_df.drop(columns=['Time'])\n",
    "    \n",
    "    # Calculate the time-series averages\n",
    "    time_series_averages = stats_to_average.mean()\n",
    "    \n",
    "    df = pd.DataFrame(time_series_averages).T\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
