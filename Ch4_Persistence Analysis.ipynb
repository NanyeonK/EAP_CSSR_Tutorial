{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch4. Persistence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the variables in empirical asset pricing research are intended to capture persistent characteristics of the entities in the sample.\n",
    "This means that the characteristic of the entity that is captured by the given variable is assumed to remain reasonably stable over time.\n",
    "\n",
    "In this chapter, we discuss a technique that we call persistence analysis. We use persistence analysis to examine whether a given characteristic of the entities in our sample is in fact persistent. Persistence analysis can also be used to examine the ability of the variable in question to capture the desired characteristic of the entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Step: calculating cross-sectional correlations between the given variable X measured a certain number of periods apart.\n",
    "\n",
    "Second Step: calculating the time-series average of each of these cross-sectional correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Persistence with Entity Column:\n",
      "               t+1       t+2       t+3       t+4       t+5\n",
      "Variable                                                  \n",
      "beta     -0.012372  0.095060  0.222180  0.313634 -0.391324\n",
      "Size     -0.077550 -0.379835  0.267808  0.534534 -0.420979\n",
      "BM       -0.120001 -0.198523  0.396845 -0.014092 -0.130984\n",
      "\n",
      "Average Persistence without Entity Column:\n",
      "               t+1       t+2       t+3       t+4       t+5\n",
      "Variable                                                  \n",
      "beta     -0.084641 -0.096246  0.034608  0.035583 -0.006334\n",
      "Size     -0.124825 -0.473607  0.182061  0.390492 -0.433567\n",
      "BM       -0.118471 -0.340782  0.142714  0.067371  0.007421\n"
     ]
    }
   ],
   "source": [
    "def calculate_cross_sectional_persistence(df, time_column, value_columns, entity_column=None, max_tau=5):\n",
    "    \"\"\"\n",
    "    Calculate the cross-sectional Pearson correlations for multiple variables measured tau periods apart for multiple tau values.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The data frame containing the data.\n",
    "        time_column (str): The name of the column representing time periods.\n",
    "        value_columns (list of str): The names of the columns representing the values of the variables.\n",
    "        entity_column (str or None): The name of the column representing the entities. If None, calculate persistence without entity grouping.\n",
    "        max_tau (int): The maximum number of periods apart to measure persistence.\n",
    "    \n",
    "    Returns:\n",
    "        dict of pd.DataFrame: A dictionary containing the persistence correlations for each variable.\n",
    "    \"\"\"\n",
    "    persistence_results = {}\n",
    "\n",
    "    for value_column in value_columns:\n",
    "        # Ensure the dataframe is sorted by the time column (and entity column if provided)\n",
    "        if entity_column:\n",
    "            df = df.sort_values(by=[time_column, entity_column]).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.sort_values(by=[time_column]).reset_index(drop=True)\n",
    "        \n",
    "        # Create a dictionary to store the results\n",
    "        results = {f't+{tau}': [] for tau in range(1, max_tau + 1)}\n",
    "        results['Year'] = []\n",
    "\n",
    "        # Get unique time periods\n",
    "        unique_times = df[time_column].unique()\n",
    "\n",
    "        # Loop over each time period\n",
    "        for t in unique_times:\n",
    "            period_df = df[df[time_column] == t]\n",
    "            \n",
    "            if len(period_df) == 0:\n",
    "                continue\n",
    "\n",
    "            correlations = []\n",
    "            \n",
    "            for tau in range(1, max_tau + 1):\n",
    "                future_time = t + tau\n",
    "                \n",
    "                if future_time not in unique_times:\n",
    "                    correlations.append(np.nan)\n",
    "                    continue\n",
    "                \n",
    "                shifted_df = df[df[time_column] == future_time]\n",
    "                \n",
    "                if entity_column:\n",
    "                    # Merge on entities to ensure we only consider those with valid values for both t and t+tau\n",
    "                    merged_df = pd.merge(period_df, shifted_df, on=entity_column, suffixes=('', f'_shifted_{tau}'))\n",
    "                else:\n",
    "                    # If no entity column, just ensure both periods have data\n",
    "                    merged_df = pd.concat([period_df.reset_index(), shifted_df.reset_index()], axis=1, keys=['t', 't+tau'])\n",
    "\n",
    "                if len(merged_df) == 0:\n",
    "                    correlations.append(np.nan)\n",
    "                    continue\n",
    "                \n",
    "                # Calculate means\n",
    "                X_t = merged_df[value_column] if entity_column else merged_df[('t', value_column)]\n",
    "                X_t_tau = merged_df[f'{value_column}_shifted_{tau}'] if entity_column else merged_df[('t+tau', value_column)]\n",
    "                mean_X_t = X_t.mean()\n",
    "                mean_X_t_tau = X_t_tau.mean()\n",
    "\n",
    "                # Calculate numerator and denominator separately\n",
    "                numerator = ((X_t - mean_X_t) * (X_t_tau - mean_X_t_tau)).sum()\n",
    "                denominator = np.sqrt(((X_t - mean_X_t) ** 2).sum() * ((X_t_tau - mean_X_t_tau) ** 2).sum())\n",
    "                \n",
    "                if denominator == 0:\n",
    "                    correlations.append(np.nan)\n",
    "                else:\n",
    "                    pearson_corr = numerator / denominator\n",
    "                    correlations.append(pearson_corr)\n",
    "            \n",
    "            results['Year'].append(t)\n",
    "            for tau, corr in zip(range(1, max_tau + 1), correlations):\n",
    "                results[f't+{tau}'].append(corr)\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.set_index('Year', inplace=True)\n",
    "        persistence_results[value_column] = results_df\n",
    "\n",
    "    return persistence_results\n",
    "\n",
    "def calculate_average_persistence(persistence_results, max_tau):\n",
    "    \"\"\"\n",
    "    Calculate the time-series average of the periodic cross-sectional correlations for multiple variables.\n",
    "    \n",
    "    Args:\n",
    "        persistence_results (dict of pd.DataFrame): A dictionary containing the periodic cross-sectional correlations for each variable.\n",
    "        max_tau (int): The maximum number of periods apart to measure persistence.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A data frame containing the average persistence values for each variable and each lag.\n",
    "    \"\"\"\n",
    "    avg_persistence = {f't+{tau}': [] for tau in range(1, max_tau + 1)}\n",
    "    avg_persistence['Variable'] = []\n",
    "\n",
    "    for variable, persistence_df in persistence_results.items():\n",
    "        avg_persistence['Variable'].append(variable)\n",
    "        for tau in range(1, max_tau + 1):\n",
    "            avg_persistence[f't+{tau}'].append(persistence_df[f't+{tau}'].mean())\n",
    "\n",
    "    avg_persistence_df = pd.DataFrame(avg_persistence)\n",
    "    avg_persistence_df.set_index('Variable', inplace=True)\n",
    "    return avg_persistence_df\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
