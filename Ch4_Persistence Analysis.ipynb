{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch4. Persistence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the variables in empirical asset pricing research are intended to capture persistent characteristics of the entities in the sample.\n",
    "This means that the characteristic of the entity that is captured by the given variable is assumed to remain reasonably stable over time.\n",
    "\n",
    "In this chapter, we discuss a technique that we call persistence analysis. We use persistence analysis to examine whether a given characteristic of the entities in our sample is in fact persistent. Persistence analysis can also be used to examine the ability of the variable in question to capture the desired characteristic of the entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Step: calculating cross-sectional correlations between the given variable X measured a certain number of periods apart.\n",
    "\n",
    "Second Step: calculating the time-series average of each of these cross-sectional correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 과정은 보통 empirical asset pricing literatures에서 보고되지 않는 경우가 많다.\n",
    "하지만, Factor zoo의 수백가지 factor가 실제 consistency를 가지는지, 어떤 방향인지, reversal을 보이는지 체크하는 것은 empirical asset pricing을 수행할 때, 매우 중요한 부분이라 판단되며,\n",
    "우리는 이 notebook들의 기초가 되는 Empirical Asset Pricing: Cross-Section of Stock Return의 Chapter 5를 확장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two step으로 이루어진다. \n",
    "1. 특정 기간 간격으로 측정된 변수 X(여기서는 firm characteristics or factor) 간의 단면 상관관계를 계산한다. \n",
    "2. 이러한 각 횡단면 correlationship의 time-series average 계산. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Periodic Cross-Sectional Persistence.    \n",
    "X와 기간 $\\tau$ 기간 간격으로 측정된 변수간의 단면 상관관계 계산.    \n",
    "time $t$와 $t+\\tau$에 속하는 각 기간에 대해 수행한다.    \n",
    "기본적인 상관관계는 pearson 상관관계를 확인한다.    \n",
    "\n",
    "$$\\rho_{t,t+\\tau} = \\frac{\\sum_{i=1}^{n_t}[(X_{i,t}-\\bar{X}_t)(X_{i,t+\\tau}-\\bar{X}_{t+\\tau})]}{\\sqrt{\\sum_{i=1}^{n_t}(X_{i,t}- \\bar{X}_t)^2} \\sqrt{\\sum_{i=1}^{n_t}(X_{i,t+\\tau}-\\bar{X}_{t+\\tau})^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\tau$가 클수록 (시차가 길 수록) $X$간의 상관관계는 낮아지는 경향이 있으나 매번 그런것은 아니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_periodic_cs_persistence(df, time_col, value_col, entity_col=None, max_tau=5):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    for value in value_col:\n",
    "        \n",
    "        if entity_col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Persistence with Entity Column:\n",
      "               t+1       t+2       t+3       t+4       t+5\n",
      "Variable                                                  \n",
      "beta     -0.012372  0.095060  0.222180  0.313634 -0.391324\n",
      "Size     -0.077550 -0.379835  0.267808  0.534534 -0.420979\n",
      "BM       -0.120001 -0.198523  0.396845 -0.014092 -0.130984\n",
      "\n",
      "Average Persistence without Entity Column:\n",
      "               t+1       t+2       t+3       t+4       t+5\n",
      "Variable                                                  \n",
      "beta     -0.084641 -0.096246  0.034608  0.035583 -0.006334\n",
      "Size     -0.124825 -0.473607  0.182061  0.390492 -0.433567\n",
      "BM       -0.118471 -0.340782  0.142714  0.067371  0.007421\n"
     ]
    }
   ],
   "source": [
    "def cal_periodic_cs_persistence(df, time_column, value_columns, entity_column=None, max_tau=5):\n",
    "    \"\"\"\n",
    "    Calculate the cross-sectional Pearson correlations for multiple variables measured tau periods apart for multiple tau values.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The data frame containing the data.\n",
    "        time_column (str): The name of the column representing time periods.\n",
    "        value_columns (list of str): The names of the columns representing the values of the variables.\n",
    "        entity_column (str or None): The name of the column representing the entities. If None, calculate persistence without entity grouping.\n",
    "        max_tau (int): The maximum number of periods apart to measure persistence.\n",
    "    \n",
    "    Returns:\n",
    "        dict of pd.DataFrame: A dictionary containing the persistence correlations for each variable.\n",
    "    \"\"\"\n",
    "    persistence_results = {}\n",
    "\n",
    "    for value_column in value_columns:\n",
    "        # Ensure the dataframe is sorted by the time column (and entity column if provided)\n",
    "        if entity_column:\n",
    "            df = df.sort_values(by=[time_column, entity_column]).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.sort_values(by=[time_column]).reset_index(drop=True)\n",
    "        \n",
    "        # Create a dictionary to store the results\n",
    "        results = {f't+{tau}': [] for tau in range(1, max_tau + 1)}\n",
    "        results['Year'] = []\n",
    "\n",
    "        # Get unique time periods\n",
    "        unique_times = df[time_column].unique()\n",
    "\n",
    "        # Loop over each time period\n",
    "        for t in unique_times:\n",
    "            period_df = df[df[time_column] == t]\n",
    "            \n",
    "            if len(period_df) == 0:\n",
    "                continue\n",
    "\n",
    "            correlations = []\n",
    "            \n",
    "            for tau in range(1, max_tau + 1):\n",
    "                future_time = t + tau\n",
    "                \n",
    "                if future_time not in unique_times:\n",
    "                    correlations.append(np.nan)\n",
    "                    continue\n",
    "                \n",
    "                shifted_df = df[df[time_column] == future_time]\n",
    "                \n",
    "                if entity_column:\n",
    "                    # Merge on entities to ensure we only consider those with valid values for both t and t+tau\n",
    "                    merged_df = pd.merge(period_df, shifted_df, on=entity_column, suffixes=('', f'_shifted_{tau}'))\n",
    "                else:\n",
    "                    # If no entity column, just ensure both periods have data\n",
    "                    merged_df = pd.concat([period_df.reset_index(), shifted_df.reset_index()], axis=1, keys=['t', 't+tau'])\n",
    "\n",
    "                if len(merged_df) == 0:\n",
    "                    correlations.append(np.nan)\n",
    "                    continue\n",
    "                \n",
    "                # Calculate means\n",
    "                X_t = merged_df[value_column] if entity_column else merged_df[('t', value_column)]\n",
    "                X_t_tau = merged_df[f'{value_column}_shifted_{tau}'] if entity_column else merged_df[('t+tau', value_column)]\n",
    "                mean_X_t = X_t.mean()\n",
    "                mean_X_t_tau = X_t_tau.mean()\n",
    "\n",
    "                # Calculate numerator and denominator separately\n",
    "                numerator = ((X_t - mean_X_t) * (X_t_tau - mean_X_t_tau)).sum()\n",
    "                denominator = np.sqrt(((X_t - mean_X_t) ** 2).sum() * ((X_t_tau - mean_X_t_tau) ** 2).sum())\n",
    "                \n",
    "                if denominator == 0:\n",
    "                    correlations.append(np.nan)\n",
    "                else:\n",
    "                    pearson_corr = numerator / denominator\n",
    "                    correlations.append(pearson_corr)\n",
    "            \n",
    "            results['Year'].append(t)\n",
    "            for tau, corr in zip(range(1, max_tau + 1), correlations):\n",
    "                results[f't+{tau}'].append(corr)\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.set_index('Year', inplace=True)\n",
    "        persistence_results[value_column] = results_df\n",
    "\n",
    "    return persistence_results\n",
    "\n",
    "def calculate_average_persistence(persistence_results, max_tau):\n",
    "    \"\"\"\n",
    "    Calculate the time-series average of the periodic cross-sectional correlations for multiple variables.\n",
    "    \n",
    "    Args:\n",
    "        persistence_results (dict of pd.DataFrame): A dictionary containing the periodic cross-sectional correlations for each variable.\n",
    "        max_tau (int): The maximum number of periods apart to measure persistence.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A data frame containing the average persistence values for each variable and each lag.\n",
    "    \"\"\"\n",
    "    avg_persistence = {f't+{tau}': [] for tau in range(1, max_tau + 1)}\n",
    "    avg_persistence['Variable'] = []\n",
    "\n",
    "    for variable, persistence_df in persistence_results.items():\n",
    "        avg_persistence['Variable'].append(variable)\n",
    "        for tau in range(1, max_tau + 1):\n",
    "            avg_persistence[f't+{tau}'].append(persistence_df[f't+{tau}'].mean())\n",
    "\n",
    "    avg_persistence_df = pd.DataFrame(avg_persistence)\n",
    "    avg_persistence_df.set_index('Variable', inplace=True)\n",
    "    return avg_persistence_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Average Cross-Sectional Persistence.  \n",
    "Periodic Cross-Sectional Persistence는 읽고 결론을 도출하기 어렵다.   \n",
    "이러한 값을 요약하기 위해 Periodic Cross-Sectional Persistence의 평균을 구한다.\n",
    "$$\\rho_{\\tau}(X) = \\frac{\\sum_{t=1}^{N-\\tau} \\rho_{t,t+\\tau}(X)}{N-\\tau}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 상관관계 변화... 어떻게 측정?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
